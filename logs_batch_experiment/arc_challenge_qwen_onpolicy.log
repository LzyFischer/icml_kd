>>> Pipeline Start: qwen_onpolicy on arc_challenge
>>> Train File: ./data/arc_challenge/train.jsonl
>>> Val File:   ./data/arc_challenge/test.jsonl
ckpts/arc_challenge/student_model_iter_3_qwen_onpolicy
INFO 01-25 22:15:40 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
usage: eval_vllm.py [-h] --model_path MODEL_PATH [--base_model BASE_MODEL]
                    --datasets DATASETS [DATASETS ...] [--data_root DATA_ROOT]
                    [--output_dir OUTPUT_DIR] [--limit LIMIT]
                    [--tp_size TP_SIZE] [--max_tokens MAX_TOKENS]
                    [--temperature TEMPERATURE]
eval_vllm.py: error: unrecognized arguments: 0.5
Successfully imported formatters from load_data.py.
>>> Pipeline Start: qwen_onpolicy on arc_challenge
>>> Train File: ./data/arc_challenge/train.jsonl
>>> Val File:   ./data/arc_challenge/test.jsonl
ckpts/arc_challenge/student_model_iter_3_qwen_onpolicy
INFO 01-26 03:43:36 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
`torch_dtype` is deprecated! Use `dtype` instead!
Successfully imported formatters from load_data.py.

[Merge] Merging adapter 'ckpts/arc_challenge/student_model_iter_3_qwen_onpolicy' into base 'unsloth/Qwen2.5-0.5B-Instruct'...
Loading vLLM from /tmp/merged_u_5da3dn...
INFO 01-26 03:43:43 [utils.py:233] non-default args: {'trust_remote_code': True, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': '/tmp/merged_u_5da3dn'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-26 03:43:43 [model.py:547] Resolved architecture: Qwen2ForCausalLM
INFO 01-26 03:43:43 [model.py:1510] Using max model len 32768
INFO 01-26 03:43:43 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
The tokenizer you are loading from '/tmp/merged_u_5da3dn' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
WARNING 01-26 03:43:44 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 01-26 03:43:46 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
Successfully imported formatters from load_data.py.
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:48 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:48 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/tmp/merged_u_5da3dn', speculative_config=None, tokenizer='/tmp/merged_u_5da3dn', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/tmp/merged_u_5da3dn, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[rank0]:[W126 03:43:50.680830094 ProcessGroupGloo.cpp:514] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:50 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2365079)[0;0m WARNING 01-26 03:43:50 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:50 [gpu_model_runner.py:2602] Starting to load model /tmp/merged_u_5da3dn...
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:50 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:50 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=2365079)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2365079)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.01it/s]
[1;36m(EngineCore_DP0 pid=2365079)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.00it/s]
[1;36m(EngineCore_DP0 pid=2365079)[0;0m 
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:50 [default_loader.py:267] Loading weights took 0.14 seconds
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:51 [gpu_model_runner.py:2653] Model loading took 0.9266 GiB and 0.252344 seconds
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:54 [backends.py:548] Using cache directory: /home/zihan/.cache/vllm/torch_compile_cache/2f47ffbc7f/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:54 [backends.py:559] Dynamo bytecode transform time: 2.54 s
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:43:56 [backends.py:197] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:04 [backends.py:218] Compiling a graph for dynamic shape takes 9.78 s
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:07 [monitor.py:34] torch.compile takes 12.32 s in total
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:08 [gpu_worker.py:298] Available KV cache memory: 60.60 GiB
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:08 [kv_cache_utils.py:1087] GPU KV cache size: 5,295,264 tokens
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:08 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 161.60x
[1;36m(EngineCore_DP0 pid=2365079)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:01, 42.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:00<00:01, 44.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 45.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 44.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:00, 43.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:00<00:00, 43.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 41.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:00<00:00, 41.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 40.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:01<00:00, 40.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:01<00:00, 38.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:01<00:00, 39.02it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:01<00:00, 40.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.65it/s]
[1;36m(EngineCore_DP0 pid=2365079)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:01, 57.60it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:00<00:00, 61.05it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:00, 62.18it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:00, 63.01it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:00<00:00, 63.20it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:00<00:00, 63.60it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:00<00:00, 63.74it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:00<00:00, 63.89it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:00<00:00, 63.89it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 63.30it/s]
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:11 [gpu_model_runner.py:3480] Graph capturing finished in 3 secs, took 0.80 GiB
[1;36m(EngineCore_DP0 pid=2365079)[0;0m INFO 01-26 03:44:11 [core.py:210] init engine (profile, create kv cache, warmup model) took 20.52 seconds
[1;36m(EngineCore_DP0 pid=2365079)[0;0m The tokenizer you are loading from '/tmp/merged_u_5da3dn' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
INFO 01-26 03:44:13 [llm.py:306] Supported_tasks: ['generate']

========================================
Processing: arc_challenge
========================================
Adding requests:   0%|          | 0/1172 [00:00<?, ?it/s]Adding requests:  18%|â–ˆâ–Š        | 208/1172 [00:00<00:00, 2077.36it/s]Adding requests:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 487/1172 [00:00<00:00, 2492.85it/s]Adding requests:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 766/1172 [00:00<00:00, 2625.31it/s]Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1050/1172 [00:00<00:00, 2709.88it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:00<00:00, 2644.73it/s]
Processed prompts:   0%|          | 0/1172 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/1172 [00:01<29:59,  1.54s/it, est. speed input: 76.15 toks/s, output: 40.35 toks/s]Processed prompts:   0%|          | 2/1172 [00:01<16:57,  1.15it/s, est. speed input: 152.12 toks/s, output: 72.71 toks/s]Processed prompts:   0%|          | 4/1172 [00:02<07:00,  2.78it/s, est. speed input: 277.36 toks/s, output: 148.18 toks/s]Processed prompts:   0%|          | 5/1172 [00:02<06:02,  3.22it/s, est. speed input: 315.88 toks/s, output: 173.91 toks/s]Processed prompts:   1%|          | 6/1172 [00:02<05:33,  3.50it/s, est. speed input: 378.56 toks/s, output: 196.93 toks/s]Processed prompts:   1%|          | 7/1172 [00:02<04:29,  4.33it/s, est. speed input: 411.39 toks/s, output: 228.29 toks/s]Processed prompts:   1%|          | 10/1172 [00:02<02:32,  7.63it/s, est. speed input: 565.38 toks/s, output: 329.56 toks/s]Processed prompts:   1%|          | 12/1172 [00:02<02:05,  9.23it/s, est. speed input: 638.50 toks/s, output: 394.12 toks/s]Processed prompts:   1%|â–         | 16/1172 [00:03<01:34, 12.24it/s, est. speed input: 789.41 toks/s, output: 517.25 toks/s]Processed prompts:   2%|â–         | 19/1172 [00:03<01:16, 15.10it/s, est. speed input: 921.98 toks/s, output: 618.59 toks/s]Processed prompts:   2%|â–         | 22/1172 [00:03<01:08, 16.76it/s, est. speed input: 1026.68 toks/s, output: 708.77 toks/s]Processed prompts:   2%|â–         | 24/1172 [00:03<01:30, 12.69it/s, est. speed input: 1028.05 toks/s, output: 731.76 toks/s]Processed prompts:   2%|â–         | 29/1172 [00:03<01:00, 18.95it/s, est. speed input: 1236.37 toks/s, output: 903.59 toks/s]Processed prompts:   3%|â–Ž         | 34/1172 [00:03<00:46, 24.50it/s, est. speed input: 1379.26 toks/s, output: 1067.91 toks/s]Processed prompts:   3%|â–Ž         | 38/1172 [00:04<00:50, 22.49it/s, est. speed input: 1469.72 toks/s, output: 1163.88 toks/s]Processed prompts:   4%|â–         | 46/1172 [00:04<00:34, 32.60it/s, est. speed input: 1714.91 toks/s, output: 1436.55 toks/s]Processed prompts:   5%|â–         | 54/1172 [00:04<00:28, 39.52it/s, est. speed input: 1954.59 toks/s, output: 1692.31 toks/s]Processed prompts:   5%|â–Œ         | 63/1172 [00:04<00:23, 48.19it/s, est. speed input: 2199.90 toks/s, output: 1989.11 toks/s]Processed prompts:   6%|â–Œ         | 69/1172 [00:04<00:23, 46.59it/s, est. speed input: 2317.95 toks/s, output: 2154.29 toks/s]Processed prompts:   6%|â–‹         | 74/1172 [00:04<00:23, 46.02it/s, est. speed input: 2419.84 toks/s, output: 2293.01 toks/s]Processed prompts:   7%|â–‹         | 82/1172 [00:04<00:20, 52.94it/s, est. speed input: 2614.05 toks/s, output: 2539.32 toks/s]Processed prompts:   8%|â–Š         | 91/1172 [00:04<00:18, 59.56it/s, est. speed input: 2826.68 toks/s, output: 2819.37 toks/s]Processed prompts:   9%|â–Š         | 101/1172 [00:05<00:17, 62.95it/s, est. speed input: 3038.09 toks/s, output: 3113.66 toks/s]Processed prompts:   9%|â–‰         | 108/1172 [00:05<00:18, 57.22it/s, est. speed input: 3151.82 toks/s, output: 3286.16 toks/s]Processed prompts:  10%|â–‰         | 114/1172 [00:05<00:21, 49.77it/s, est. speed input: 3221.77 toks/s, output: 3405.61 toks/s]Processed prompts:  10%|â–ˆ         | 120/1172 [00:05<00:20, 50.34it/s, est. speed input: 3319.58 toks/s, output: 3557.96 toks/s]Processed prompts:  11%|â–ˆ         | 129/1172 [00:05<00:18, 57.81it/s, est. speed input: 3500.95 toks/s, output: 3822.39 toks/s]Processed prompts:  12%|â–ˆâ–        | 136/1172 [00:05<00:17, 59.53it/s, est. speed input: 3604.78 toks/s, output: 4008.65 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 147/1172 [00:05<00:15, 68.12it/s, est. speed input: 3804.16 toks/s, output: 4331.06 toks/s]Processed prompts:  14%|â–ˆâ–Ž        | 160/1172 [00:05<00:12, 79.92it/s, est. speed input: 4052.61 toks/s, output: 4723.69 toks/s]Processed prompts:  14%|â–ˆâ–        | 169/1172 [00:06<00:12, 78.37it/s, est. speed input: 4190.65 toks/s, output: 4963.64 toks/s]Processed prompts:  15%|â–ˆâ–Œ        | 180/1172 [00:06<00:11, 83.12it/s, est. speed input: 4396.99 toks/s, output: 5276.91 toks/s]Processed prompts:  16%|â–ˆâ–Œ        | 189/1172 [00:06<00:12, 81.25it/s, est. speed input: 4528.96 toks/s, output: 5511.90 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 198/1172 [00:06<00:11, 81.34it/s, est. speed input: 4650.13 toks/s, output: 5727.29 toks/s]Processed prompts:  18%|â–ˆâ–Š        | 211/1172 [00:06<00:10, 91.46it/s, est. speed input: 4867.98 toks/s, output: 6109.18 toks/s]Processed prompts:  19%|â–ˆâ–‰        | 221/1172 [00:06<00:10, 93.00it/s, est. speed input: 5010.73 toks/s, output: 6383.27 toks/s]Processed prompts:  20%|â–ˆâ–‰        | 231/1172 [00:06<00:11, 84.91it/s, est. speed input: 5121.18 toks/s, output: 6617.91 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 240/1172 [00:06<00:11, 83.61it/s, est. speed input: 5224.14 toks/s, output: 6841.32 toks/s]Processed prompts:  21%|â–ˆâ–ˆâ–       | 250/1172 [00:07<00:10, 85.29it/s, est. speed input: 5348.72 toks/s, output: 7098.93 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 259/1172 [00:07<00:10, 85.08it/s, est. speed input: 5444.64 toks/s, output: 7321.35 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 268/1172 [00:07<00:11, 79.14it/s, est. speed input: 5539.11 toks/s, output: 7515.29 toks/s]Processed prompts:  24%|â–ˆâ–ˆâ–Ž       | 277/1172 [00:07<00:11, 81.26it/s, est. speed input: 5643.24 toks/s, output: 7741.16 toks/s]Processed prompts:  25%|â–ˆâ–ˆâ–Œ       | 295/1172 [00:07<00:08, 102.51it/s, est. speed input: 5915.35 toks/s, output: 8264.26 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 312/1172 [00:07<00:07, 118.36it/s, est. speed input: 6172.87 toks/s, output: 8754.26 toks/s]Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 324/1172 [00:07<00:07, 117.26it/s, est. speed input: 6311.17 toks/s, output: 9078.07 toks/s]Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 341/1172 [00:07<00:06, 128.05it/s, est. speed input: 6540.68 toks/s, output: 9550.00 toks/s]Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 365/1172 [00:07<00:05, 148.60it/s, est. speed input: 6887.15 toks/s, output: 10279.31 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 384/1172 [00:08<00:04, 158.77it/s, est. speed input: 7148.40 toks/s, output: 10833.62 toks/s]Processed prompts:  35%|â–ˆâ–ˆâ–ˆâ–      | 405/1172 [00:08<00:04, 159.99it/s, est. speed input: 7413.84 toks/s, output: 11433.47 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 428/1172 [00:08<00:04, 174.79it/s, est. speed input: 7748.20 toks/s, output: 12130.03 toks/s]Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 448/1172 [00:08<00:04, 178.65it/s, est. speed input: 8025.99 toks/s, output: 12710.93 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 466/1172 [00:08<00:04, 165.57it/s, est. speed input: 8226.96 toks/s, output: 13156.57 toks/s]Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 485/1172 [00:08<00:04, 170.31it/s, est. speed input: 8461.68 toks/s, output: 13652.54 toks/s]Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 519/1172 [00:08<00:03, 203.72it/s, est. speed input: 8926.54 toks/s, output: 14689.04 toks/s]Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 542/1172 [00:08<00:02, 210.78it/s, est. speed input: 9218.77 toks/s, output: 15349.19 toks/s]Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 575/1172 [00:08<00:02, 231.37it/s, est. speed input: 9645.93 toks/s, output: 16360.11 toks/s]Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 607/1172 [00:09<00:02, 247.01it/s, est. speed input: 10079.36 toks/s, output: 17320.32 toks/s]Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 632/1172 [00:09<00:02, 240.92it/s, est. speed input: 10381.73 toks/s, output: 18005.16 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 668/1172 [00:09<00:01, 272.19it/s, est. speed input: 10868.30 toks/s, output: 19114.80 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 702/1172 [00:09<00:01, 288.20it/s, est. speed input: 11308.80 toks/s, output: 20174.63 toks/s]Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 732/1172 [00:09<00:01, 288.08it/s, est. speed input: 11687.68 toks/s, output: 21087.81 toks/s]Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 769/1172 [00:09<00:01, 303.80it/s, est. speed input: 12173.91 toks/s, output: 22222.92 toks/s]Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 803/1172 [00:09<00:01, 313.94it/s, est. speed input: 12591.23 toks/s, output: 23277.78 toks/s]Processed prompts:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 835/1172 [00:09<00:01, 311.94it/s, est. speed input: 12956.62 toks/s, output: 24273.54 toks/s]Processed prompts:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 873/1172 [00:09<00:00, 326.65it/s, est. speed input: 13417.39 toks/s, output: 25477.70 toks/s]Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 916/1172 [00:10<00:00, 354.39it/s, est. speed input: 13979.35 toks/s, output: 26894.91 toks/s]Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 952/1172 [00:10<00:00, 327.35it/s, est. speed input: 14376.76 toks/s, output: 27897.11 toks/s]Processed prompts:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 990/1172 [00:10<00:00, 339.97it/s, est. speed input: 14831.87 toks/s, output: 29101.85 toks/s]Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1028/1172 [00:10<00:00, 349.43it/s, est. speed input: 15295.97 toks/s, output: 30362.67 toks/s]Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1064/1172 [00:10<00:00, 320.44it/s, est. speed input: 15647.53 toks/s, output: 31392.09 toks/s]Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1097/1172 [00:10<00:00, 309.69it/s, est. speed input: 16004.45 toks/s, output: 32273.73 toks/s]Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1129/1172 [00:10<00:00, 308.21it/s, est. speed input: 16310.39 toks/s, output: 33153.30 toks/s]Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1161/1172 [00:10<00:00, 228.93it/s, est. speed input: 16442.26 toks/s, output: 33670.60 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:14<00:00, 228.93it/s, est. speed input: 12888.50 toks/s, output: 26650.90 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:14<00:00, 83.08it/s, est. speed input: 12888.50 toks/s, output: 26650.90 toks/s] 
[rank0]:[W126 03:44:27.489812093 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Accuracy for arc_challenge: 40.53%
Saved results to: results_final/arc_challenge/student_model_iter_3_qwen_onpolicy/eval_results.json
>>> Pipeline Start: qwen_onpolicy on arc_challenge
>>> Train File: ./data/arc_challenge/train.jsonl
>>> Val File:   ./data/arc_challenge/test.jsonl
ckpts/arc_challenge/student_model_iter_2_qwen_onpolicy
INFO 01-26 08:36:19 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
`torch_dtype` is deprecated! Use `dtype` instead!
Successfully imported formatters from load_data.py.

[Merge] Merging adapter 'ckpts/arc_challenge/student_model_iter_2_qwen_onpolicy' into base 'unsloth/Qwen2.5-0.5B-Instruct'...
Loading vLLM from /tmp/merged_jb44trco...
INFO 01-26 08:36:27 [utils.py:233] non-default args: {'trust_remote_code': True, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': '/tmp/merged_jb44trco'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-26 08:36:27 [model.py:547] Resolved architecture: Qwen2ForCausalLM
INFO 01-26 08:36:27 [model.py:1510] Using max model len 32768
INFO 01-26 08:36:27 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
The tokenizer you are loading from '/tmp/merged_jb44trco' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
WARNING 01-26 08:36:27 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 01-26 08:36:30 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
Successfully imported formatters from load_data.py.
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:32 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:32 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/tmp/merged_jb44trco', speculative_config=None, tokenizer='/tmp/merged_jb44trco', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/tmp/merged_jb44trco, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[rank0]:[W126 08:36:33.915303503 ProcessGroupGloo.cpp:514] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:33 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2684988)[0;0m WARNING 01-26 08:36:33 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:33 [gpu_model_runner.py:2602] Starting to load model /tmp/merged_jb44trco...
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:33 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:33 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=2684988)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2684988)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.40it/s]
[1;36m(EngineCore_DP0 pid=2684988)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.39it/s]
[1;36m(EngineCore_DP0 pid=2684988)[0;0m 
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:34 [default_loader.py:267] Loading weights took 0.16 seconds
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:34 [gpu_model_runner.py:2653] Model loading took 0.9266 GiB and 0.276838 seconds
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:37 [backends.py:548] Using cache directory: /home/zihan/.cache/vllm/torch_compile_cache/d4c67cdbcf/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:37 [backends.py:559] Dynamo bytecode transform time: 2.54 s
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:39 [backends.py:197] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:47 [backends.py:218] Compiling a graph for dynamic shape takes 9.77 s
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:50 [monitor.py:34] torch.compile takes 12.31 s in total
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:51 [gpu_worker.py:298] Available KV cache memory: 60.60 GiB
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:51 [kv_cache_utils.py:1087] GPU KV cache size: 5,295,264 tokens
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:51 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 161.60x
[1;36m(EngineCore_DP0 pid=2684988)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:01, 42.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:00<00:01, 44.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 45.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 44.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:00, 43.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:00<00:00, 43.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 41.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:00<00:00, 38.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:01<00:00, 27.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:01<00:00, 30.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:01<00:00, 31.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:01<00:00, 32.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 35.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 37.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 36.94it/s]
[1;36m(EngineCore_DP0 pid=2684988)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:01, 55.22it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:00<00:00, 59.03it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:00, 51.37it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:00, 54.97it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:00<00:00, 56.97it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:00<00:00, 58.67it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:00<00:00, 59.91it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:00<00:00, 60.42it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 59.88it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 58.50it/s]
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:55 [gpu_model_runner.py:3480] Graph capturing finished in 4 secs, took 0.80 GiB
[1;36m(EngineCore_DP0 pid=2684988)[0;0m INFO 01-26 08:36:55 [core.py:210] init engine (profile, create kv cache, warmup model) took 20.84 seconds
[1;36m(EngineCore_DP0 pid=2684988)[0;0m The tokenizer you are loading from '/tmp/merged_jb44trco' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
INFO 01-26 08:36:56 [llm.py:306] Supported_tasks: ['generate']

========================================
Processing: arc_challenge
========================================
Adding requests:   0%|          | 0/1172 [00:00<?, ?it/s]Adding requests:  22%|â–ˆâ–ˆâ–       | 260/1172 [00:00<00:00, 2595.37it/s]Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 520/1172 [00:00<00:00, 2558.90it/s]Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 790/1172 [00:00<00:00, 2621.57it/s]Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1055/1172 [00:00<00:00, 2629.18it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:00<00:00, 2625.12it/s]
Processed prompts:   0%|          | 0/1172 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/1172 [00:02<39:33,  2.03s/it, est. speed input: 58.70 toks/s, output: 42.42 toks/s]Processed prompts:   0%|          | 2/1172 [00:02<19:24,  1.00it/s, est. speed input: 105.19 toks/s, output: 78.68 toks/s]Processed prompts:   0%|          | 3/1172 [00:02<14:44,  1.32it/s, est. speed input: 129.46 toks/s, output: 106.74 toks/s]Processed prompts:   0%|          | 4/1172 [00:02<10:04,  1.93it/s, est. speed input: 162.41 toks/s, output: 143.26 toks/s]Processed prompts:   1%|          | 6/1172 [00:03<05:16,  3.68it/s, est. speed input: 240.16 toks/s, output: 220.37 toks/s]Processed prompts:   1%|          | 7/1172 [00:03<04:22,  4.43it/s, est. speed input: 287.03 toks/s, output: 253.22 toks/s]Processed prompts:   1%|          | 9/1172 [00:03<03:13,  6.02it/s, est. speed input: 367.58 toks/s, output: 321.14 toks/s]Processed prompts:   1%|          | 11/1172 [00:03<02:33,  7.56it/s, est. speed input: 454.90 toks/s, output: 386.66 toks/s]Processed prompts:   2%|â–         | 18/1172 [00:03<01:21, 14.21it/s, est. speed input: 687.28 toks/s, output: 630.33 toks/s]Processed prompts:   2%|â–         | 20/1172 [00:03<01:16, 14.97it/s, est. speed input: 769.00 toks/s, output: 693.11 toks/s]Processed prompts:   2%|â–         | 29/1172 [00:03<00:41, 27.79it/s, est. speed input: 1101.02 toks/s, output: 1030.95 toks/s]Processed prompts:   3%|â–Ž         | 33/1172 [00:04<00:42, 26.83it/s, est. speed input: 1208.81 toks/s, output: 1147.56 toks/s]Processed prompts:   3%|â–Ž         | 37/1172 [00:04<00:39, 28.43it/s, est. speed input: 1314.09 toks/s, output: 1274.32 toks/s]Processed prompts:   4%|â–         | 45/1172 [00:04<00:29, 38.14it/s, est. speed input: 1546.70 toks/s, output: 1551.95 toks/s]Processed prompts:   5%|â–         | 53/1172 [00:04<00:24, 45.93it/s, est. speed input: 1763.07 toks/s, output: 1824.57 toks/s]Processed prompts:   5%|â–Œ         | 59/1172 [00:04<00:27, 40.46it/s, est. speed input: 1876.02 toks/s, output: 1982.89 toks/s]Processed prompts:   5%|â–Œ         | 64/1172 [00:04<00:28, 39.31it/s, est. speed input: 1967.37 toks/s, output: 2123.73 toks/s]Processed prompts:   6%|â–Œ         | 71/1172 [00:04<00:25, 43.80it/s, est. speed input: 2126.08 toks/s, output: 2342.26 toks/s]Processed prompts:   7%|â–‹         | 77/1172 [00:05<00:25, 42.68it/s, est. speed input: 2277.52 toks/s, output: 2506.81 toks/s]Processed prompts:   8%|â–Š         | 89/1172 [00:05<00:20, 54.12it/s, est. speed input: 2537.61 toks/s, output: 2891.20 toks/s]Processed prompts:   8%|â–Š         | 99/1172 [00:05<00:17, 62.02it/s, est. speed input: 2772.87 toks/s, output: 3209.36 toks/s]Processed prompts:   9%|â–‰         | 106/1172 [00:05<00:17, 61.09it/s, est. speed input: 2919.60 toks/s, output: 3406.46 toks/s]Processed prompts:  10%|â–‰         | 113/1172 [00:05<00:18, 57.63it/s, est. speed input: 3042.30 toks/s, output: 3590.72 toks/s]Processed prompts:  10%|â–ˆ         | 119/1172 [00:05<00:18, 55.87it/s, est. speed input: 3137.89 toks/s, output: 3746.41 toks/s]Processed prompts:  11%|â–ˆ         | 126/1172 [00:05<00:17, 58.88it/s, est. speed input: 3281.14 toks/s, output: 3948.24 toks/s]Processed prompts:  12%|â–ˆâ–        | 139/1172 [00:05<00:14, 73.21it/s, est. speed input: 3521.81 toks/s, output: 4359.62 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 147/1172 [00:06<00:14, 72.42it/s, est. speed input: 3691.54 toks/s, output: 4581.37 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 156/1172 [00:06<00:13, 73.52it/s, est. speed input: 3834.53 toks/s, output: 4833.14 toks/s]Processed prompts:  14%|â–ˆâ–        | 164/1172 [00:06<00:15, 64.21it/s, est. speed input: 3919.92 toks/s, output: 5008.74 toks/s]Processed prompts:  15%|â–ˆâ–Œ        | 179/1172 [00:06<00:12, 82.05it/s, est. speed input: 4223.87 toks/s, output: 5484.99 toks/s]Processed prompts:  16%|â–ˆâ–Œ        | 189/1172 [00:06<00:12, 81.49it/s, est. speed input: 4370.76 toks/s, output: 5755.66 toks/s]Processed prompts:  18%|â–ˆâ–Š        | 208/1172 [00:06<00:09, 105.27it/s, est. speed input: 4707.07 toks/s, output: 6370.23 toks/s]Processed prompts:  19%|â–ˆâ–Š        | 219/1172 [00:06<00:09, 102.19it/s, est. speed input: 4862.69 toks/s, output: 6653.96 toks/s]Processed prompts:  20%|â–ˆâ–‰        | 232/1172 [00:06<00:09, 99.34it/s, est. speed input: 5047.77 toks/s, output: 7007.57 toks/s] Processed prompts:  21%|â–ˆâ–ˆ        | 245/1172 [00:07<00:08, 104.17it/s, est. speed input: 5233.44 toks/s, output: 7382.74 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 256/1172 [00:07<00:08, 102.29it/s, est. speed input: 5376.39 toks/s, output: 7679.05 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 270/1172 [00:07<00:08, 108.81it/s, est. speed input: 5566.72 toks/s, output: 8083.28 toks/s]Processed prompts:  25%|â–ˆâ–ˆâ–       | 289/1172 [00:07<00:07, 123.99it/s, est. speed input: 5842.49 toks/s, output: 8663.32 toks/s]Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 302/1172 [00:07<00:07, 123.18it/s, est. speed input: 6009.78 toks/s, output: 9002.77 toks/s]Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 324/1172 [00:07<00:05, 147.18it/s, est. speed input: 6357.39 toks/s, output: 9702.06 toks/s]Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 342/1172 [00:07<00:05, 153.47it/s, est. speed input: 6608.93 toks/s, output: 10238.21 toks/s]Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 358/1172 [00:07<00:05, 145.65it/s, est. speed input: 6808.24 toks/s, output: 10671.47 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 381/1172 [00:07<00:04, 167.75it/s, est. speed input: 7153.74 toks/s, output: 11377.94 toks/s]Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 401/1172 [00:08<00:04, 166.38it/s, est. speed input: 7413.92 toks/s, output: 11951.25 toks/s]Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 418/1172 [00:08<00:04, 159.94it/s, est. speed input: 7618.29 toks/s, output: 12417.24 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 435/1172 [00:08<00:04, 162.14it/s, est. speed input: 7834.98 toks/s, output: 12903.57 toks/s]Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 458/1172 [00:08<00:03, 180.43it/s, est. speed input: 8140.44 toks/s, output: 13592.38 toks/s]Processed prompts:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 482/1172 [00:08<00:03, 184.67it/s, est. speed input: 8464.23 toks/s, output: 14276.63 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 506/1172 [00:08<00:03, 188.25it/s, est. speed input: 8769.24 toks/s, output: 14974.55 toks/s]Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 537/1172 [00:08<00:02, 211.88it/s, est. speed input: 9187.02 toks/s, output: 15942.16 toks/s]Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 559/1172 [00:08<00:03, 203.22it/s, est. speed input: 9428.79 toks/s, output: 16556.13 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 581/1172 [00:09<00:02, 199.10it/s, est. speed input: 9677.45 toks/s, output: 17168.70 toks/s]Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 613/1172 [00:09<00:02, 222.49it/s, est. speed input: 10086.86 toks/s, output: 18124.95 toks/s]Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 641/1172 [00:09<00:02, 228.73it/s, est. speed input: 10418.41 toks/s, output: 18956.65 toks/s]Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 674/1172 [00:09<00:01, 251.30it/s, est. speed input: 10842.46 toks/s, output: 19991.82 toks/s]Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 713/1172 [00:09<00:01, 288.18it/s, est. speed input: 11379.77 toks/s, output: 21267.39 toks/s]Processed prompts:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 756/1172 [00:09<00:01, 320.15it/s, est. speed input: 11972.99 toks/s, output: 22679.78 toks/s]Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 804/1172 [00:09<00:01, 356.30it/s, est. speed input: 12602.63 toks/s, output: 24263.64 toks/s]Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 847/1172 [00:09<00:00, 367.39it/s, est. speed input: 13178.25 toks/s, output: 25649.88 toks/s]Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 886/1172 [00:09<00:00, 373.36it/s, est. speed input: 13692.52 toks/s, output: 26929.18 toks/s]Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 925/1172 [00:09<00:00, 370.68it/s, est. speed input: 14192.64 toks/s, output: 28214.62 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 976/1172 [00:10<00:00, 410.03it/s, est. speed input: 14908.88 toks/s, output: 29961.34 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1018/1172 [00:10<00:00, 386.92it/s, est. speed input: 15407.42 toks/s, output: 31266.86 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1058/1172 [00:10<00:00, 310.33it/s, est. speed input: 15754.74 toks/s, output: 32235.39 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1092/1172 [00:10<00:00, 296.56it/s, est. speed input: 16072.24 toks/s, output: 33000.86 toks/s]Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1124/1172 [00:10<00:00, 258.92it/s, est. speed input: 16284.58 toks/s, output: 33564.53 toks/s]Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1152/1172 [00:10<00:00, 215.70it/s, est. speed input: 16390.84 toks/s, output: 33965.75 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:13<00:00, 215.70it/s, est. speed input: 13026.22 toks/s, output: 27306.74 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1172/1172 [00:13<00:00, 83.96it/s, est. speed input: 13026.22 toks/s, output: 27306.74 toks/s] 
[rank0]:[W126 08:37:11.925415258 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Accuracy for arc_challenge: 39.25%
Saved results to: results_final/arc_challenge/student_model_iter_2_qwen_onpolicy/eval_results.json
