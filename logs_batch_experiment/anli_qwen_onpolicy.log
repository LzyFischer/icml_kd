>>> Pipeline Start: qwen_onpolicy on anli
>>> Train File: ./data/anli/train.jsonl
>>> Val File:   ./data/anli/test.jsonl
ckpts/anli/student_model_iter_3_qwen_onpolicy
INFO 01-25 21:04:43 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
`torch_dtype` is deprecated! Use `dtype` instead!
Successfully imported formatters from load_data.py.

[Merge] Merging adapter 'ckpts/anli/student_model_iter_3_qwen_onpolicy' into base 'unsloth/Qwen2.5-0.5B-Instruct'...
Loading vLLM from /tmp/merged_mk1yullq...
INFO 01-25 21:04:50 [utils.py:233] non-default args: {'trust_remote_code': True, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': '/tmp/merged_mk1yullq'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-25 21:04:50 [model.py:547] Resolved architecture: Qwen2ForCausalLM
INFO 01-25 21:04:50 [model.py:1510] Using max model len 32768
INFO 01-25 21:04:50 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
The tokenizer you are loading from '/tmp/merged_mk1yullq' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
WARNING 01-25 21:04:50 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 01-25 21:04:53 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
Successfully imported formatters from load_data.py.
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:55 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:55 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/tmp/merged_mk1yullq', speculative_config=None, tokenizer='/tmp/merged_mk1yullq', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/tmp/merged_mk1yullq, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[rank0]:[W125 21:04:56.223906318 ProcessGroupGloo.cpp:514] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:56 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=1977081)[0;0m WARNING 01-25 21:04:56 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:56 [gpu_model_runner.py:2602] Starting to load model /tmp/merged_mk1yullq...
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:57 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:57 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=1977081)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=1977081)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.73it/s]
[1;36m(EngineCore_DP0 pid=1977081)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.72it/s]
[1;36m(EngineCore_DP0 pid=1977081)[0;0m 
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:57 [default_loader.py:267] Loading weights took 0.15 seconds
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:04:57 [gpu_model_runner.py:2653] Model loading took 0.9266 GiB and 0.261101 seconds
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:00 [backends.py:548] Using cache directory: /home/zihan/.cache/vllm/torch_compile_cache/067c57cf23/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:00 [backends.py:559] Dynamo bytecode transform time: 2.53 s
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:02 [backends.py:197] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:10 [backends.py:218] Compiling a graph for dynamic shape takes 9.94 s
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:14 [monitor.py:34] torch.compile takes 12.47 s in total
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:14 [gpu_worker.py:298] Available KV cache memory: 60.60 GiB
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:15 [kv_cache_utils.py:1087] GPU KV cache size: 5,295,264 tokens
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:15 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 161.60x
[1;36m(EngineCore_DP0 pid=1977081)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:01, 42.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:00<00:01, 44.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 45.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 44.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:00, 43.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:00<00:00, 43.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 41.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:00<00:00, 41.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 39.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:01<00:00, 39.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:01<00:00, 38.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:01<00:00, 38.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:01<00:00, 40.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.50it/s]
[1;36m(EngineCore_DP0 pid=1977081)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:01, 57.16it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:00<00:00, 60.64it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:00, 61.79it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:00, 62.64it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:00<00:00, 62.82it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:00<00:00, 63.25it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:00<00:00, 63.44it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:00<00:00, 62.49it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:00<00:00, 62.88it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 62.72it/s]
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:18 [gpu_model_runner.py:3480] Graph capturing finished in 3 secs, took 0.80 GiB
[1;36m(EngineCore_DP0 pid=1977081)[0;0m INFO 01-25 21:05:18 [core.py:210] init engine (profile, create kv cache, warmup model) took 20.72 seconds
[1;36m(EngineCore_DP0 pid=1977081)[0;0m The tokenizer you are loading from '/tmp/merged_mk1yullq' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
INFO 01-25 21:05:19 [llm.py:306] Supported_tasks: ['generate']

========================================
Processing: anli
========================================
Loading anli from: ./data/anli/test.jsonl
Adding requests:   0%|          | 0/1200 [00:00<?, ?it/s]Adding requests:  20%|â–ˆâ–‰        | 237/1200 [00:00<00:00, 2369.21it/s]Adding requests:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 551/1200 [00:00<00:00, 2821.81it/s]Adding requests:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 847/1200 [00:00<00:00, 2882.63it/s]Adding requests:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1136/1200 [00:00<00:00, 2874.88it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:00<00:00, 2841.35it/s]
Processed prompts:   0%|          | 0/1200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/1200 [00:01<35:17,  1.77s/it, est. speed input: 86.64 toks/s, output: 44.73 toks/s]Processed prompts:   0%|          | 2/1200 [00:02<18:51,  1.06it/s, est. speed input: 161.61 toks/s, output: 84.79 toks/s]Processed prompts:   0%|          | 4/1200 [00:02<08:32,  2.33it/s, est. speed input: 239.33 toks/s, output: 164.88 toks/s]Processed prompts:   0%|          | 6/1200 [00:02<06:02,  3.30it/s, est. speed input: 309.74 toks/s, output: 231.38 toks/s]Processed prompts:   1%|          | 8/1200 [00:02<04:00,  4.96it/s, est. speed input: 411.51 toks/s, output: 314.95 toks/s]Processed prompts:   1%|          | 10/1200 [00:02<02:57,  6.72it/s, est. speed input: 502.26 toks/s, output: 394.06 toks/s]Processed prompts:   1%|â–         | 16/1200 [00:03<01:21, 14.56it/s, est. speed input: 816.29 toks/s, output: 650.38 toks/s]Processed prompts:   2%|â–         | 20/1200 [00:03<01:04, 18.17it/s, est. speed input: 988.81 toks/s, output: 802.27 toks/s]Processed prompts:   2%|â–         | 25/1200 [00:03<00:48, 24.12it/s, est. speed input: 1175.32 toks/s, output: 1001.17 toks/s]Processed prompts:   3%|â–Ž         | 31/1200 [00:03<00:39, 29.92it/s, est. speed input: 1416.23 toks/s, output: 1230.73 toks/s]Processed prompts:   3%|â–Ž         | 37/1200 [00:03<00:32, 35.74it/s, est. speed input: 1599.64 toks/s, output: 1454.65 toks/s]Processed prompts:   4%|â–         | 46/1200 [00:03<00:25, 45.55it/s, est. speed input: 1888.84 toks/s, output: 1797.25 toks/s]Processed prompts:   5%|â–         | 59/1200 [00:03<00:18, 61.48it/s, est. speed input: 2333.40 toks/s, output: 2301.16 toks/s]Processed prompts:   6%|â–Œ         | 70/1200 [00:03<00:15, 71.84it/s, est. speed input: 2662.18 toks/s, output: 2713.40 toks/s]Processed prompts:   6%|â–‹         | 78/1200 [00:03<00:15, 72.97it/s, est. speed input: 2850.93 toks/s, output: 2987.99 toks/s]Processed prompts:   7%|â–‹         | 87/1200 [00:04<00:14, 75.04it/s, est. speed input: 3064.39 toks/s, output: 3294.94 toks/s]Processed prompts:   8%|â–Š         | 98/1200 [00:04<00:13, 82.04it/s, est. speed input: 3352.28 toks/s, output: 3681.46 toks/s]Processed prompts:   9%|â–‰         | 113/1200 [00:04<00:11, 95.98it/s, est. speed input: 3740.56 toks/s, output: 4223.47 toks/s]Processed prompts:  10%|â–ˆ         | 126/1200 [00:04<00:10, 101.82it/s, est. speed input: 4040.15 toks/s, output: 4666.43 toks/s]Processed prompts:  12%|â–ˆâ–        | 140/1200 [00:04<00:10, 105.94it/s, est. speed input: 4376.11 toks/s, output: 5130.00 toks/s]Processed prompts:  14%|â–ˆâ–Ž        | 162/1200 [00:04<00:07, 133.14it/s, est. speed input: 4912.75 toks/s, output: 5933.05 toks/s]Processed prompts:  15%|â–ˆâ–        | 176/1200 [00:04<00:07, 133.20it/s, est. speed input: 5207.06 toks/s, output: 6391.31 toks/s]Processed prompts:  16%|â–ˆâ–Œ        | 193/1200 [00:04<00:07, 139.51it/s, est. speed input: 5595.37 toks/s, output: 6962.79 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 208/1200 [00:04<00:07, 141.56it/s, est. speed input: 5917.90 toks/s, output: 7448.98 toks/s]Processed prompts:  19%|â–ˆâ–Š        | 223/1200 [00:05<00:07, 133.66it/s, est. speed input: 6162.83 toks/s, output: 7892.71 toks/s]Processed prompts:  21%|â–ˆâ–ˆ        | 248/1200 [00:05<00:05, 161.69it/s, est. speed input: 6712.23 toks/s, output: 8768.74 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 269/1200 [00:05<00:05, 168.56it/s, est. speed input: 7119.73 toks/s, output: 9454.82 toks/s]Processed prompts:  24%|â–ˆâ–ˆâ–       | 288/1200 [00:05<00:05, 174.32it/s, est. speed input: 7432.11 toks/s, output: 10069.59 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 319/1200 [00:05<00:04, 200.79it/s, est. speed input: 8014.56 toks/s, output: 11134.91 toks/s]Processed prompts:  29%|â–ˆâ–ˆâ–‰       | 349/1200 [00:05<00:03, 214.35it/s, est. speed input: 8572.78 toks/s, output: 12137.75 toks/s]Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 383/1200 [00:05<00:03, 235.10it/s, est. speed input: 9197.34 toks/s, output: 13286.55 toks/s]Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 409/1200 [00:05<00:03, 232.75it/s, est. speed input: 9616.26 toks/s, output: 14100.10 toks/s]Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 437/1200 [00:06<00:03, 243.84it/s, est. speed input: 10121.76 toks/s, output: 15000.77 toks/s]Processed prompts:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 468/1200 [00:06<00:02, 249.78it/s, est. speed input: 10606.27 toks/s, output: 15994.47 toks/s]Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 499/1200 [00:06<00:02, 253.59it/s, est. speed input: 11098.59 toks/s, output: 16977.17 toks/s]Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 525/1200 [00:06<00:02, 247.51it/s, est. speed input: 11459.18 toks/s, output: 17755.58 toks/s]Processed prompts:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 558/1200 [00:06<00:02, 262.19it/s, est. speed input: 11983.61 toks/s, output: 18823.69 toks/s]Processed prompts:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 593/1200 [00:06<00:02, 277.25it/s, est. speed input: 12564.90 toks/s, output: 19932.02 toks/s]Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 621/1200 [00:06<00:02, 273.58it/s, est. speed input: 12999.23 toks/s, output: 20780.58 toks/s]Processed prompts:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 656/1200 [00:06<00:01, 291.85it/s, est. speed input: 13541.96 toks/s, output: 21924.70 toks/s]Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 691/1200 [00:06<00:01, 298.89it/s, est. speed input: 14033.35 toks/s, output: 23039.55 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 721/1200 [00:06<00:01, 295.56it/s, est. speed input: 14434.85 toks/s, output: 23942.26 toks/s]Processed prompts:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 773/1200 [00:07<00:01, 350.36it/s, est. speed input: 15216.82 toks/s, output: 25777.98 toks/s]Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 814/1200 [00:07<00:01, 358.05it/s, est. speed input: 15767.19 toks/s, output: 27092.41 toks/s]Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 858/1200 [00:07<00:00, 363.32it/s, est. speed input: 16380.53 toks/s, output: 28496.74 toks/s]Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 900/1200 [00:07<00:00, 370.88it/s, est. speed input: 16900.45 toks/s, output: 29921.54 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 955/1200 [00:07<00:00, 415.66it/s, est. speed input: 17691.67 toks/s, output: 31910.97 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1000/1200 [00:07<00:00, 421.14it/s, est. speed input: 18262.99 toks/s, output: 33350.59 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1043/1200 [00:07<00:00, 369.12it/s, est. speed input: 18609.71 toks/s, output: 34393.83 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1082/1200 [00:07<00:00, 331.96it/s, est. speed input: 18951.40 toks/s, output: 35435.69 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1120/1200 [00:08<00:00, 343.67it/s, est. speed input: 19321.71 toks/s, output: 36524.09 toks/s]Processed prompts:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1156/1200 [00:08<00:00, 311.83it/s, est. speed input: 19552.59 toks/s, output: 37224.70 toks/s]Processed prompts:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1189/1200 [00:08<00:00, 222.64it/s, est. speed input: 19483.91 toks/s, output: 37541.55 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:12<00:00, 222.64it/s, est. speed input: 13816.94 toks/s, output: 27220.14 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:12<00:00, 99.65it/s, est. speed input: 13816.94 toks/s, output: 27220.14 toks/s] 
[rank0]:[W125 21:05:32.214883941 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Accuracy for anli: 32.67%
Saved results to: results_final/anli/student_model_iter_3_qwen_onpolicy/eval_results.json
>>> Pipeline Start: qwen_onpolicy on anli
>>> Train File: ./data/anli/train.jsonl
>>> Val File:   ./data/anli/test.jsonl
ckpts/anli/student_model_iter_3_qwen_onpolicy
INFO 01-25 21:47:47 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
usage: eval_vllm.py [-h] --model_path MODEL_PATH [--base_model BASE_MODEL]
                    --datasets DATASETS [DATASETS ...] [--data_root DATA_ROOT]
                    [--output_dir OUTPUT_DIR] [--limit LIMIT]
                    [--tp_size TP_SIZE] [--max_tokens MAX_TOKENS]
                    [--temperature TEMPERATURE]
eval_vllm.py: error: unrecognized arguments: 0.5
Successfully imported formatters from load_data.py.
>>> Pipeline Start: qwen_onpolicy on anli
>>> Train File: ./data/anli/train.jsonl
>>> Val File:   ./data/anli/test.jsonl
ckpts/anli/student_model_iter_3_qwen_onpolicy
INFO 01-26 02:57:20 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
`torch_dtype` is deprecated! Use `dtype` instead!
Successfully imported formatters from load_data.py.

[Merge] Merging adapter 'ckpts/anli/student_model_iter_3_qwen_onpolicy' into base 'unsloth/Qwen2.5-0.5B-Instruct'...
Loading vLLM from /tmp/merged_4u3wzd_n...
INFO 01-26 02:57:27 [utils.py:233] non-default args: {'trust_remote_code': True, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': '/tmp/merged_4u3wzd_n'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-26 02:57:27 [model.py:547] Resolved architecture: Qwen2ForCausalLM
INFO 01-26 02:57:27 [model.py:1510] Using max model len 32768
INFO 01-26 02:57:27 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
The tokenizer you are loading from '/tmp/merged_4u3wzd_n' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
WARNING 01-26 02:57:28 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 01-26 02:57:30 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
Successfully imported formatters from load_data.py.
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:32 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:32 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/tmp/merged_4u3wzd_n', speculative_config=None, tokenizer='/tmp/merged_4u3wzd_n', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/tmp/merged_4u3wzd_n, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[rank0]:[W126 02:57:34.689053151 ProcessGroupGloo.cpp:514] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:34 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2295527)[0;0m WARNING 01-26 02:57:34 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:34 [gpu_model_runner.py:2602] Starting to load model /tmp/merged_4u3wzd_n...
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:34 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:34 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=2295527)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2295527)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.73it/s]
[1;36m(EngineCore_DP0 pid=2295527)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.71it/s]
[1;36m(EngineCore_DP0 pid=2295527)[0;0m 
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:34 [default_loader.py:267] Loading weights took 0.15 seconds
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:35 [gpu_model_runner.py:2653] Model loading took 0.9266 GiB and 0.259930 seconds
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:38 [backends.py:548] Using cache directory: /home/zihan/.cache/vllm/torch_compile_cache/a9f40224ac/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:38 [backends.py:559] Dynamo bytecode transform time: 2.54 s
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:40 [backends.py:197] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:48 [backends.py:218] Compiling a graph for dynamic shape takes 9.89 s
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:51 [monitor.py:34] torch.compile takes 12.43 s in total
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:52 [gpu_worker.py:298] Available KV cache memory: 60.60 GiB
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:52 [kv_cache_utils.py:1087] GPU KV cache size: 5,295,264 tokens
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:52 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 161.60x
[1;36m(EngineCore_DP0 pid=2295527)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:01, 42.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:00<00:01, 44.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 45.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 44.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:00, 43.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:00<00:00, 43.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 41.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:00<00:00, 40.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 39.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:01<00:00, 39.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:01<00:00, 38.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:01<00:00, 38.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:01<00:00, 40.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.39it/s]
[1;36m(EngineCore_DP0 pid=2295527)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:01, 51.93it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:00<00:00, 57.92it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:00, 59.53it/s]Capturing CUDA graphs (decode, FULL):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:00<00:00, 55.57it/s]Capturing CUDA graphs (decode, FULL):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:00<00:00, 36.03it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:00<00:00, 39.15it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:00<00:00, 43.28it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:01<00:00, 44.52it/s]Capturing CUDA graphs (decode, FULL):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:01<00:00, 48.61it/s]Capturing CUDA graphs (decode, FULL):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:01<00:00, 51.25it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 54.29it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 48.79it/s]
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:56 [gpu_model_runner.py:3480] Graph capturing finished in 4 secs, took 0.80 GiB
[1;36m(EngineCore_DP0 pid=2295527)[0;0m INFO 01-26 02:57:56 [core.py:210] init engine (profile, create kv cache, warmup model) took 20.99 seconds
[1;36m(EngineCore_DP0 pid=2295527)[0;0m The tokenizer you are loading from '/tmp/merged_4u3wzd_n' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
INFO 01-26 02:57:57 [llm.py:306] Supported_tasks: ['generate']

========================================
Processing: anli
========================================
Adding requests:   0%|          | 0/1200 [00:00<?, ?it/s]Adding requests:  15%|â–ˆâ–Œ        | 180/1200 [00:00<00:00, 1798.69it/s]Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 483/1200 [00:00<00:00, 2521.00it/s]Adding requests:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 786/1200 [00:00<00:00, 2750.34it/s]Adding requests:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1062/1200 [00:00<00:00, 2714.17it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:00<00:00, 2657.57it/s]
Processed prompts:   0%|          | 0/1200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/1200 [00:01<32:28,  1.62s/it, est. speed input: 104.02 toks/s, output: 42.47 toks/s]Processed prompts:   0%|          | 2/1200 [00:01<15:30,  1.29it/s, est. speed input: 184.82 toks/s, output: 76.91 toks/s]Processed prompts:   0%|          | 3/1200 [00:01<10:02,  1.99it/s, est. speed input: 274.39 toks/s, output: 111.26 toks/s]Processed prompts:   0%|          | 4/1200 [00:02<07:40,  2.60it/s, est. speed input: 357.59 toks/s, output: 141.57 toks/s]Processed prompts:   0%|          | 6/1200 [00:02<04:25,  4.49it/s, est. speed input: 445.76 toks/s, output: 210.94 toks/s]Processed prompts:   1%|          | 13/1200 [00:02<01:30, 13.14it/s, est. speed input: 799.62 toks/s, output: 465.00 toks/s]Processed prompts:   2%|â–         | 18/1200 [00:02<01:03, 18.62it/s, est. speed input: 1053.25 toks/s, output: 635.62 toks/s]Processed prompts:   2%|â–         | 22/1200 [00:02<00:53, 21.91it/s, est. speed input: 1279.51 toks/s, output: 764.84 toks/s]Processed prompts:   2%|â–         | 26/1200 [00:02<00:51, 22.69it/s, est. speed input: 1421.28 toks/s, output: 876.09 toks/s]Processed prompts:   2%|â–Ž         | 30/1200 [00:03<00:48, 24.36it/s, est. speed input: 1523.51 toks/s, output: 987.25 toks/s]Processed prompts:   3%|â–Ž         | 38/1200 [00:03<00:33, 34.96it/s, est. speed input: 1828.23 toks/s, output: 1250.29 toks/s]Processed prompts:   4%|â–         | 47/1200 [00:03<00:25, 46.00it/s, est. speed input: 2198.18 toks/s, output: 1542.89 toks/s]Processed prompts:   4%|â–         | 54/1200 [00:03<00:22, 49.88it/s, est. speed input: 2418.02 toks/s, output: 1752.59 toks/s]Processed prompts:   5%|â–Œ         | 65/1200 [00:03<00:18, 60.88it/s, est. speed input: 2781.66 toks/s, output: 2099.01 toks/s]Processed prompts:   6%|â–Œ         | 72/1200 [00:03<00:20, 55.80it/s, est. speed input: 2941.81 toks/s, output: 2271.29 toks/s]Processed prompts:   7%|â–‹         | 79/1200 [00:03<00:19, 57.42it/s, est. speed input: 3084.10 toks/s, output: 2459.18 toks/s]Processed prompts:   7%|â–‹         | 88/1200 [00:03<00:17, 61.83it/s, est. speed input: 3316.05 toks/s, output: 2713.14 toks/s]Processed prompts:   8%|â–Š         | 95/1200 [00:04<00:19, 57.49it/s, est. speed input: 3460.03 toks/s, output: 2873.47 toks/s]Processed prompts:   8%|â–Š         | 102/1200 [00:04<00:19, 57.60it/s, est. speed input: 3578.85 toks/s, output: 3045.94 toks/s]Processed prompts:   9%|â–‰         | 109/1200 [00:04<00:18, 57.98it/s, est. speed input: 3724.60 toks/s, output: 3218.90 toks/s]Processed prompts:  10%|â–‰         | 118/1200 [00:04<00:17, 63.32it/s, est. speed input: 3905.22 toks/s, output: 3464.95 toks/s]Processed prompts:  11%|â–ˆâ–        | 135/1200 [00:04<00:12, 84.88it/s, est. speed input: 4356.15 toks/s, output: 3988.70 toks/s]Processed prompts:  12%|â–ˆâ–Ž        | 150/1200 [00:04<00:10, 96.34it/s, est. speed input: 4724.62 toks/s, output: 4429.28 toks/s]Processed prompts:  14%|â–ˆâ–Ž        | 162/1200 [00:04<00:10, 97.08it/s, est. speed input: 4987.91 toks/s, output: 4753.66 toks/s]Processed prompts:  15%|â–ˆâ–Œ        | 181/1200 [00:04<00:08, 113.39it/s, est. speed input: 5405.56 toks/s, output: 5314.05 toks/s]Processed prompts:  16%|â–ˆâ–‹        | 198/1200 [00:05<00:08, 122.14it/s, est. speed input: 5740.09 toks/s, output: 5801.59 toks/s]Processed prompts:  18%|â–ˆâ–Š        | 221/1200 [00:05<00:06, 144.15it/s, est. speed input: 6234.14 toks/s, output: 6499.27 toks/s]Processed prompts:  20%|â–ˆâ–‰        | 236/1200 [00:05<00:06, 140.34it/s, est. speed input: 6471.94 toks/s, output: 6899.74 toks/s]Processed prompts:  21%|â–ˆâ–ˆ        | 251/1200 [00:05<00:06, 142.26it/s, est. speed input: 6731.17 toks/s, output: 7308.77 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 268/1200 [00:05<00:06, 142.04it/s, est. speed input: 7038.80 toks/s, output: 7755.38 toks/s]Processed prompts:  24%|â–ˆâ–ˆâ–       | 287/1200 [00:05<00:06, 150.40it/s, est. speed input: 7360.27 toks/s, output: 8279.23 toks/s]Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 308/1200 [00:05<00:05, 162.97it/s, est. speed input: 7742.82 toks/s, output: 8872.55 toks/s]Processed prompts:  28%|â–ˆâ–ˆâ–Š       | 333/1200 [00:05<00:04, 182.13it/s, est. speed input: 8202.13 toks/s, output: 9600.57 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–‰       | 357/1200 [00:05<00:04, 182.83it/s, est. speed input: 8597.15 toks/s, output: 10245.52 toks/s]Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 383/1200 [00:06<00:04, 199.45it/s, est. speed input: 9021.78 toks/s, output: 10995.75 toks/s]Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 407/1200 [00:06<00:03, 209.41it/s, est. speed input: 9443.14 toks/s, output: 11675.11 toks/s]Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 429/1200 [00:06<00:03, 203.95it/s, est. speed input: 9745.12 toks/s, output: 12252.34 toks/s]Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 452/1200 [00:06<00:03, 208.22it/s, est. speed input: 10095.38 toks/s, output: 12876.98 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 476/1200 [00:06<00:03, 215.07it/s, est. speed input: 10403.27 toks/s, output: 13531.58 toks/s]Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 498/1200 [00:06<00:03, 216.02it/s, est. speed input: 10693.89 toks/s, output: 14097.90 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 520/1200 [00:06<00:03, 215.02it/s, est. speed input: 10968.84 toks/s, output: 14677.74 toks/s]Processed prompts:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 545/1200 [00:06<00:03, 209.54it/s, est. speed input: 11268.73 toks/s, output: 15307.94 toks/s]Processed prompts:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 572/1200 [00:06<00:02, 214.77it/s, est. speed input: 11599.99 toks/s, output: 16022.39 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 594/1200 [00:07<00:02, 206.55it/s, est. speed input: 11842.85 toks/s, output: 16553.88 toks/s]Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 626/1200 [00:07<00:02, 223.50it/s, est. speed input: 12288.81 toks/s, output: 17407.05 toks/s]Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 649/1200 [00:07<00:02, 225.15it/s, est. speed input: 12535.37 toks/s, output: 18005.10 toks/s]Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 672/1200 [00:07<00:02, 223.51it/s, est. speed input: 12787.94 toks/s, output: 18590.94 toks/s]Processed prompts:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 697/1200 [00:07<00:02, 230.30it/s, est. speed input: 13070.64 toks/s, output: 19226.85 toks/s]Processed prompts:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 735/1200 [00:07<00:01, 268.10it/s, est. speed input: 13564.51 toks/s, output: 20324.63 toks/s]Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 787/1200 [00:07<00:01, 330.09it/s, est. speed input: 14305.94 toks/s, output: 21935.36 toks/s]Processed prompts:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 826/1200 [00:07<00:01, 345.45it/s, est. speed input: 14784.09 toks/s, output: 23044.26 toks/s]Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 869/1200 [00:07<00:00, 366.80it/s, est. speed input: 15354.33 toks/s, output: 24294.66 toks/s]Processed prompts:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 908/1200 [00:07<00:00, 369.87it/s, est. speed input: 15842.04 toks/s, output: 25481.28 toks/s]Processed prompts:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 946/1200 [00:08<00:00, 353.31it/s, est. speed input: 16235.81 toks/s, output: 26520.02 toks/s]Processed prompts:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 984/1200 [00:08<00:00, 354.64it/s, est. speed input: 16698.75 toks/s, output: 27592.29 toks/s]Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1020/1200 [00:08<00:00, 353.14it/s, est. speed input: 17063.22 toks/s, output: 28626.88 toks/s]Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1059/1200 [00:08<00:00, 358.61it/s, est. speed input: 17464.19 toks/s, output: 29682.92 toks/s]Processed prompts:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1096/1200 [00:08<00:00, 355.35it/s, est. speed input: 17828.47 toks/s, output: 30638.62 toks/s]Processed prompts:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1132/1200 [00:08<00:00, 331.47it/s, est. speed input: 18172.96 toks/s, output: 31506.53 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1166/1200 [00:08<00:00, 302.58it/s, est. speed input: 18410.52 toks/s, output: 32362.77 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1197/1200 [00:09<00:00, 214.28it/s, est. speed input: 18367.19 toks/s, output: 32723.08 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:12<00:00, 214.28it/s, est. speed input: 13140.55 toks/s, output: 23718.87 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:12<00:00, 94.77it/s, est. speed input: 13140.55 toks/s, output: 23718.87 toks/s] 
[rank0]:[W126 02:58:10.467487557 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Accuracy for anli: 32.67%
Saved results to: results_final/anli/student_model_iter_3_qwen_onpolicy/eval_results.json
run_iterative_pipeline.sh: illegal option -- e
Usage: run_iterative_pipeline.sh [options]
Options:
  -i <int>    Number of iterations (default: 2)
  -b <str>    Base Student Model
  -t <str>    Teacher Model
  -f <str>    Original Train File (required for generation source)
  -v <str>    Validation File
  -s <str>    Start Student Checkpoint (optional)
  -n <str>    Run Name Suffix (unique identifier)
  -h          Show this help message
>>> Pipeline Start: qwen_onpolicy on anli
>>> Train File: ./data/anli/train.jsonl
>>> Val File:   ./data/anli/test.jsonl
ckpts/anli/student_model_iter_2_qwen_onpolicy
INFO 01-26 07:54:58 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
`torch_dtype` is deprecated! Use `dtype` instead!
Successfully imported formatters from load_data.py.

[Merge] Merging adapter 'ckpts/anli/student_model_iter_2_qwen_onpolicy' into base 'unsloth/Qwen2.5-0.5B-Instruct'...
Loading vLLM from /tmp/merged_w1t9v3kz...
INFO 01-26 07:55:05 [utils.py:233] non-default args: {'trust_remote_code': True, 'gpu_memory_utilization': 0.85, 'disable_log_stats': True, 'model': '/tmp/merged_w1t9v3kz'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-26 07:55:05 [model.py:547] Resolved architecture: Qwen2ForCausalLM
INFO 01-26 07:55:05 [model.py:1510] Using max model len 32768
INFO 01-26 07:55:05 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
The tokenizer you are loading from '/tmp/merged_w1t9v3kz' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
WARNING 01-26 07:55:06 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 01-26 07:55:08 [__init__.py:216] Automatically detected platform cuda.
Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info
Successfully imported formatters from load_data.py.
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:10 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:10 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/tmp/merged_w1t9v3kz', speculative_config=None, tokenizer='/tmp/merged_w1t9v3kz', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/tmp/merged_w1t9v3kz, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[rank0]:[W126 07:55:12.632584818 ProcessGroupGloo.cpp:514] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:12 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2622020)[0;0m WARNING 01-26 07:55:12 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:12 [gpu_model_runner.py:2602] Starting to load model /tmp/merged_w1t9v3kz...
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:12 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:12 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=2622020)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2622020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.88it/s]
[1;36m(EngineCore_DP0 pid=2622020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.87it/s]
[1;36m(EngineCore_DP0 pid=2622020)[0;0m 
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:12 [default_loader.py:267] Loading weights took 0.17 seconds
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:13 [gpu_model_runner.py:2653] Model loading took 0.9266 GiB and 0.282776 seconds
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:16 [backends.py:548] Using cache directory: /home/zihan/.cache/vllm/torch_compile_cache/0155056489/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:16 [backends.py:559] Dynamo bytecode transform time: 2.55 s
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:18 [backends.py:197] Cache the graph for dynamic shape for later use
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:26 [backends.py:218] Compiling a graph for dynamic shape takes 9.81 s
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:29 [monitor.py:34] torch.compile takes 12.35 s in total
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:30 [gpu_worker.py:298] Available KV cache memory: 60.60 GiB
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:30 [kv_cache_utils.py:1087] GPU KV cache size: 5,295,264 tokens
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:30 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 161.60x
[1;36m(EngineCore_DP0 pid=2622020)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:01, 42.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:00<00:01, 44.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 44.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 44.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:00, 43.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:00<00:00, 43.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 41.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:00<00:00, 40.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 39.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:01<00:00, 39.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:01<00:00, 28.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:01<00:00, 30.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 33.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 36.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 37.88it/s]
[1;36m(EngineCore_DP0 pid=2622020)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:01, 55.89it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:00<00:00, 59.56it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:00, 60.18it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:00, 61.23it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:00<00:00, 61.48it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:00<00:00, 62.09it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:00<00:00, 62.15it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:00<00:00, 62.46it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 62.51it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 61.82it/s]
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:34 [gpu_model_runner.py:3480] Graph capturing finished in 3 secs, took 0.80 GiB
[1;36m(EngineCore_DP0 pid=2622020)[0;0m INFO 01-26 07:55:34 [core.py:210] init engine (profile, create kv cache, warmup model) took 20.81 seconds
[1;36m(EngineCore_DP0 pid=2622020)[0;0m The tokenizer you are loading from '/tmp/merged_w1t9v3kz' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.
INFO 01-26 07:55:35 [llm.py:306] Supported_tasks: ['generate']

========================================
Processing: anli
========================================
Adding requests:   0%|          | 0/1200 [00:00<?, ?it/s]Adding requests:  18%|â–ˆâ–Š        | 214/1200 [00:00<00:00, 2138.62it/s]Adding requests:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 526/1200 [00:00<00:00, 2713.09it/s]Adding requests:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 823/1200 [00:00<00:00, 2830.21it/s]Adding requests:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1107/1200 [00:00<00:00, 2788.39it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:00<00:00, 2747.31it/s]
Processed prompts:   0%|          | 0/1200 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 1/1200 [00:00<18:56,  1.06it/s, est. speed input: 110.79 toks/s, output: 43.26 toks/s]Processed prompts:   0%|          | 2/1200 [00:01<09:49,  2.03it/s, est. speed input: 228.39 toks/s, output: 82.07 toks/s]Processed prompts:   0%|          | 3/1200 [00:01<07:07,  2.80it/s, est. speed input: 337.93 toks/s, output: 113.91 toks/s]Processed prompts:   0%|          | 4/1200 [00:01<05:28,  3.64it/s, est. speed input: 427.34 toks/s, output: 146.09 toks/s]Processed prompts:   0%|          | 5/1200 [00:01<04:34,  4.36it/s, est. speed input: 507.85 toks/s, output: 175.89 toks/s]Processed prompts:   0%|          | 6/1200 [00:01<03:51,  5.17it/s, est. speed input: 555.15 toks/s, output: 205.95 toks/s]Processed prompts:   1%|          | 8/1200 [00:01<02:29,  7.98it/s, est. speed input: 642.72 toks/s, output: 273.21 toks/s]Processed prompts:   1%|          | 11/1200 [00:02<01:43, 11.47it/s, est. speed input: 791.77 toks/s, output: 370.15 toks/s]Processed prompts:   1%|          | 13/1200 [00:02<01:53, 10.46it/s, est. speed input: 868.74 toks/s, output: 414.83 toks/s]Processed prompts:   1%|â–         | 15/1200 [00:02<01:37, 12.10it/s, est. speed input: 944.25 toks/s, output: 478.32 toks/s]Processed prompts:   2%|â–         | 19/1200 [00:02<01:17, 15.33it/s, est. speed input: 1080.85 toks/s, output: 599.10 toks/s]Processed prompts:   2%|â–         | 21/1200 [00:02<01:12, 16.19it/s, est. speed input: 1148.14 toks/s, output: 656.34 toks/s]Processed prompts:   2%|â–         | 23/1200 [00:02<01:24, 13.86it/s, est. speed input: 1180.53 toks/s, output: 688.08 toks/s]Processed prompts:   2%|â–Ž         | 30/1200 [00:02<00:47, 24.75it/s, est. speed input: 1477.19 toks/s, output: 935.85 toks/s]Processed prompts:   3%|â–Ž         | 38/1200 [00:03<00:32, 35.83it/s, est. speed input: 1780.44 toks/s, output: 1213.21 toks/s]Processed prompts:   4%|â–Ž         | 43/1200 [00:03<00:30, 38.47it/s, est. speed input: 1960.54 toks/s, output: 1368.07 toks/s]Processed prompts:   4%|â–         | 48/1200 [00:03<00:28, 40.20it/s, est. speed input: 2094.94 toks/s, output: 1516.50 toks/s]Processed prompts:   5%|â–         | 55/1200 [00:03<00:27, 41.30it/s, est. speed input: 2276.36 toks/s, output: 1712.34 toks/s]Processed prompts:   5%|â–Œ         | 61/1200 [00:03<00:25, 44.53it/s, est. speed input: 2463.21 toks/s, output: 1891.59 toks/s]Processed prompts:   6%|â–Œ         | 66/1200 [00:03<00:25, 44.65it/s, est. speed input: 2572.71 toks/s, output: 2024.73 toks/s]Processed prompts:   6%|â–Œ         | 71/1200 [00:03<00:26, 42.43it/s, est. speed input: 2636.20 toks/s, output: 2147.47 toks/s]Processed prompts:   7%|â–‹         | 82/1200 [00:03<00:19, 56.49it/s, est. speed input: 2938.43 toks/s, output: 2504.15 toks/s]Processed prompts:   8%|â–Š         | 90/1200 [00:04<00:18, 60.25it/s, est. speed input: 3186.52 toks/s, output: 2743.01 toks/s]Processed prompts:   8%|â–Š         | 97/1200 [00:04<00:18, 60.50it/s, est. speed input: 3310.49 toks/s, output: 2937.36 toks/s]Processed prompts:   9%|â–‰         | 105/1200 [00:04<00:17, 62.01it/s, est. speed input: 3483.49 toks/s, output: 3158.99 toks/s]Processed prompts:  10%|â–‰         | 115/1200 [00:04<00:15, 68.19it/s, est. speed input: 3685.94 toks/s, output: 3451.27 toks/s]Processed prompts:  11%|â–ˆ         | 127/1200 [00:04<00:13, 77.20it/s, est. speed input: 4001.35 toks/s, output: 3813.39 toks/s]Processed prompts:  12%|â–ˆâ–        | 144/1200 [00:04<00:11, 95.13it/s, est. speed input: 4403.75 toks/s, output: 4350.68 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 154/1200 [00:04<00:12, 87.14it/s, est. speed input: 4598.20 toks/s, output: 4597.14 toks/s]Processed prompts:  14%|â–ˆâ–Ž        | 164/1200 [00:04<00:11, 86.77it/s, est. speed input: 4778.26 toks/s, output: 4861.98 toks/s]Processed prompts:  14%|â–ˆâ–        | 173/1200 [00:05<00:12, 84.53it/s, est. speed input: 4921.26 toks/s, output: 5085.54 toks/s]Processed prompts:  15%|â–ˆâ–Œ        | 182/1200 [00:05<00:12, 81.08it/s, est. speed input: 5050.11 toks/s, output: 5299.50 toks/s]Processed prompts:  16%|â–ˆâ–Œ        | 194/1200 [00:05<00:11, 86.52it/s, est. speed input: 5319.66 toks/s, output: 5630.10 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 209/1200 [00:05<00:10, 97.91it/s, est. speed input: 5600.97 toks/s, output: 6062.47 toks/s]Processed prompts:  19%|â–ˆâ–‰        | 225/1200 [00:05<00:08, 109.42it/s, est. speed input: 5868.31 toks/s, output: 6527.68 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 246/1200 [00:05<00:07, 128.58it/s, est. speed input: 6265.34 toks/s, output: 7161.32 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 264/1200 [00:05<00:06, 136.06it/s, est. speed input: 6602.07 toks/s, output: 7681.05 toks/s]Processed prompts:  24%|â–ˆâ–ˆâ–       | 290/1200 [00:05<00:05, 162.23it/s, est. speed input: 7135.33 toks/s, output: 8491.44 toks/s]Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 307/1200 [00:05<00:05, 154.72it/s, est. speed input: 7368.18 toks/s, output: 8941.81 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 326/1200 [00:06<00:05, 160.26it/s, est. speed input: 7675.25 toks/s, output: 9481.19 toks/s]Processed prompts:  29%|â–ˆâ–ˆâ–Š       | 343/1200 [00:06<00:05, 159.56it/s, est. speed input: 7919.26 toks/s, output: 9930.83 toks/s]Processed prompts:  31%|â–ˆâ–ˆâ–ˆ       | 367/1200 [00:06<00:04, 177.14it/s, est. speed input: 8306.21 toks/s, output: 10637.24 toks/s]Processed prompts:  32%|â–ˆâ–ˆâ–ˆâ–      | 388/1200 [00:06<00:04, 184.76it/s, est. speed input: 8620.30 toks/s, output: 11237.51 toks/s]Processed prompts:  34%|â–ˆâ–ˆâ–ˆâ–      | 407/1200 [00:06<00:04, 185.21it/s, est. speed input: 8887.14 toks/s, output: 11761.72 toks/s]Processed prompts:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 435/1200 [00:06<00:03, 208.69it/s, est. speed input: 9341.91 toks/s, output: 12609.47 toks/s]Processed prompts:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 456/1200 [00:06<00:03, 207.55it/s, est. speed input: 9633.14 toks/s, output: 13195.04 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 478/1200 [00:06<00:03, 204.46it/s, est. speed input: 9931.43 toks/s, output: 13788.68 toks/s]Processed prompts:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 502/1200 [00:06<00:03, 211.02it/s, est. speed input: 10292.34 toks/s, output: 14451.65 toks/s]Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 524/1200 [00:07<00:03, 212.26it/s, est. speed input: 10548.15 toks/s, output: 15016.74 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 559/1200 [00:07<00:02, 238.35it/s, est. speed input: 11041.64 toks/s, output: 16058.57 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 597/1200 [00:07<00:02, 262.65it/s, est. speed input: 11563.24 toks/s, output: 17159.55 toks/s]Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 623/1200 [00:07<00:02, 248.78it/s, est. speed input: 11861.40 toks/s, output: 17846.56 toks/s]Processed prompts:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 648/1200 [00:07<00:02, 239.51it/s, est. speed input: 12114.19 toks/s, output: 18491.85 toks/s]Processed prompts:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 673/1200 [00:07<00:02, 239.61it/s, est. speed input: 12415.50 toks/s, output: 19163.24 toks/s]Processed prompts:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 707/1200 [00:07<00:01, 262.09it/s, est. speed input: 12837.96 toks/s, output: 20130.46 toks/s]Processed prompts:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 750/1200 [00:07<00:01, 305.98it/s, est. speed input: 13426.66 toks/s, output: 21446.51 toks/s]Processed prompts:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 788/1200 [00:07<00:01, 321.22it/s, est. speed input: 13942.26 toks/s, output: 22576.05 toks/s]Processed prompts:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 821/1200 [00:08<00:01, 315.69it/s, est. speed input: 14355.15 toks/s, output: 23485.72 toks/s]Processed prompts:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 862/1200 [00:08<00:01, 338.00it/s, est. speed input: 14842.12 toks/s, output: 24644.35 toks/s]Processed prompts:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 896/1200 [00:08<00:00, 326.89it/s, est. speed input: 15183.42 toks/s, output: 25580.50 toks/s]Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 931/1200 [00:08<00:00, 328.07it/s, est. speed input: 15586.37 toks/s, output: 26554.34 toks/s]Processed prompts:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 975/1200 [00:08<00:00, 357.38it/s, est. speed input: 16115.03 toks/s, output: 27987.28 toks/s]Processed prompts:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1022/1200 [00:08<00:00, 388.74it/s, est. speed input: 16662.28 toks/s, output: 29418.93 toks/s]Processed prompts:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1062/1200 [00:08<00:00, 387.18it/s, est. speed input: 17054.26 toks/s, output: 30571.00 toks/s]Processed prompts:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1104/1200 [00:08<00:00, 387.12it/s, est. speed input: 17461.69 toks/s, output: 31748.20 toks/s]Processed prompts:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1143/1200 [00:08<00:00, 357.35it/s, est. speed input: 17794.49 toks/s, output: 32721.13 toks/s]Processed prompts:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1180/1200 [00:09<00:00, 290.04it/s, est. speed input: 18008.00 toks/s, output: 33550.63 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:09<00:00, 290.04it/s, est. speed input: 17254.31 toks/s, output: 32506.31 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:09<00:00, 124.44it/s, est. speed input: 17254.31 toks/s, output: 32506.31 toks/s]
[rank0]:[W126 07:55:45.254559710 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Accuracy for anli: 34.17%
Saved results to: results_final/anli/student_model_iter_2_qwen_onpolicy/eval_results.json
